\section{Goals}

Our goal is to build a machine learning model that can find out which group a participant belongs to (\textit{control group} or the \textit{condition group}).
There are several ways this can be acheived, and two ideas came to our minds. The first one was a bit naive, and was to simply throw in the columns from the 
demographics dataset \ref{figure:demographics}. We did not expect much from this, as there is only 55 rows in the table. Anyone having a little bit experience 
with machine learning will know that this is not nearly enough data. But we wanted to do it regardless, and see how a simple and stupid model performed.
Doing this, we would also establish some sort of benchmark for performance; the second model must do \textit{at least} better than this one.

The other idea was to use the activity measurements as time series data, and create a one-dimentional Convolutional Neural Network (1D-CNN). We knew that 
CNNs are used a lot today on image recognition, but is a bit different as images are two-dimentional data, and our measurements are in \textit{one} dimention.

\subsection{Regression}

We decided to use a regression classifier for the first idea. However the dataset is not structured in a way such that we can just throw it into Keras.
First and foremost, most values in this table are blank for participants in the \textit{control group}, so it does only make sense to predict within 
the \textit{condition group}. 

The columns \textbf{number} and \textbf{days} should be dropped, as they probably have nothing to do with the result. 
The column \textbf{afftype} is be the column the regression model should guess, so it needed to be in a separate table (X = input table, y = output table).

Both the \textit{age} and \textit{education} columns are strings with values that the actual value is within. For example the participant \textbf{condition\_1} 
has age = \textbf{35-39} and edu = \textbf{6-10}. It would be better to change this to one value, and we decided to use the median of the two values.
Also, we changed some other values to make more sense. \textit{Melanch, inpatient, marriage, work and gender} are \textbf{binary} values, 
so we changed them to be either 0 or 1. We also changed \textit{afftype} (terniary value) to between 0 and 2 instead of between 1 and 3.

\newpage
After the changes, the tables should be read the following way:

X:
\begin{itemize}
  \item \textbf{gender}: 0 = male, 1 = female
  \item \textbf{age}: Median value of age range
  \item \textbf{melanch}: 0 = does not have melancholia, 1 = has melancholia
  \item \textbf{inpatient}: 0 = outpatient, 1 = inpatient
  \item \textbf{edu}: Median value of education range
  \item \textbf{marriage}: 0 = single, 1 = married (or cohabiting)
  \item \textbf{work}: 0 = not working, 1 = working
  \item \textbf{madrs1}: MADRS score before activity measurements
  \item \textbf{madrs2}: MADRS score after activity measurements
\end{itemize}

y:
\begin{itemize}
  \item \textbf{afftype}: 0 = bipolar II, 1 = unipolar depressive, 2 = bipolar I
\end{itemize}

\subsection{Convolutional Neural Network}

As we said before, we wanted to use a Convolutional Neural Network to classify which group a given participant most likely belongs to.

\subsubsection{Learning experiments}

We needed to learn more about CNNs. CNNs are used in image recognition, so we proceeded to implement one. We found a tutorial on how to make 
a 2D CNN for classifying cats and dogs from images \cite{2d_cnn}, and thought it would be a good way to learn.

It was both a fun and informative experience implementing this. Especially when we extended the script to allow an image url to predict on. 
Then we could browse for any image of a cat or a dog, and find out if the model could handle it (in most cases it did!). 
We even tried inputting images of humans to the model for fun. This experiment resulted in a lot of motivation for our task.

However as mentioned before, our data is one-dimentional, so a two-dimentional CNN would not be useful.

\begin{quote}
  \textit{A 1D CNN is very effective when you expect to derive interesting features from shorter (fixed-length) segments of the overall data set 
  and where the location of the feature within the segment is not of high relevance. This applies well to the analysis of time sequences of sensor data 
  (such as gyroscope or accelerometer data).} \cite{1d_cnn}
\end{quote}

To learn more about 1D CNNs, we followed a tutorial \cite{1d_cnn}, which used a dataset containing 
time-sliced accelerometer data from a smartphone on the participants waists. The goal for this CNN is to predict what a given person is doing 
at the time, given the accelerometer data for that time slice. What the given person is doing is one of the following:
\begin{itemize}
  \item Standing
  \item Walking
  \item Jogging
  \item Sitting
  \item Upstairs
  \item Downstairs
\end{itemize}

As we followed the tutorial and implemented the model, we learned a lot about how 1D CNNs work and how we should structure our own data. 
In machine learning it is common to normalize data values, which is important to for example make up for differences in features. 
There are built in ways to automatically do this, but you can also make your own \textit{normalizer}, which was done in this tutorial in the following way, 
and is the one we ended up using in our activity measurement classifier as well:

\begin{code}
  \caption{Feature Normalizer}
  \label{code:feature_normalizer}
  
  \begin{minted}[linenos]{python}
    def feature_normalize(dataset):
        mu = np.mean(dataset, axis=0)
        sigma = np.std(dataset, axis=0)
        return (dataset - mu)/sigma
  \end{minted}
\end{code}

We also learned where our dataset could provide more data. 
What if the dataset contained the current mental state of the bipolar patient? Then someone could make some automated system that always can tell a patient 
whether they are normal, manic or depressive. However data collection for this kind of task would be difficult because we can't always know what the
patient thinks, nor does the patient themselves. The "tutorial" dataset is different because it is easy to differientiate physical states of the body
like standing or walking.

\subsubsection{Classification based on activity measurements}

The input data was quite different for this kind task. We wanted the input data to the model to be a list containing activity measurements for all participants,
and somehow label them \textbf{[NOT BIPOLAR]} or \textbf{[BIPOLAR]}. We ended up using time-slices of measurements, 
as previously learned in the tutorial \cite{1d_cnn}.

We created a list where for each participant in the demographics table \ref{figure:demographics}, measurements for four hours were grouped. 
Another choice we learned from the tutorial was to overlap the sequences, so we made the next group of four hours start \textit{one} hour after, 
and not \textit{four} hours after the group before, like one might think. When this list was complete with sequences from all participants, we 
had to \textbf{reshape} it so that it could fit into a neural network. We ended up with a feature list (which we called \textbf{segments}), 
where each element was a list of activity measurements for 4 hours: 

\textbf{segments[0] = [[0], [143], [0], [20], [166], [160], [306], [277], [439], ...]}

\noindent A second list was created simultaneously, with the value \textbf{0} or \textbf{1} for the labels \textbf{[NOT BIPOLAR]} and \textbf{[BIPOLAR]}.
This value was chosen according to the group the participants were in. Using a helper function from Keras, \textbf{to\_categorical}, we transformed this 
list of labels into to columns, \textbf{[NOT BIPOLAR]} and \textbf{[BIPOLAR]}, where only one of the columns have the value 1 for each row. Transforming 
the values to a categorical table is required for the neural network that we ended up building, to be able to select a \textit{category} for the result. 
This list, which we called \textbf{labels}, looked like this: 

\textbf{labels[0] = [0, 1]}

\noindent Meaning that the first segment is labelled as \textbf{[BIPOLAR]}.

\section{Metrics}

\section{Benchmarks}
